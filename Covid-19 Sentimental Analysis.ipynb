{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685ac55-7c92-4646-ac61-6861f9e3f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import random\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "plt.rc('figure', figsize=(17, 13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a549b41-6783-4499-a23d-2ebdfb85566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = pd.read_csv(\"C:\\\\Users\\\\USER\\\\Downloads\\\\archive\\\\vaccination_tweets.csv\")\n",
    "f_data.text = f_data.text.str.lower()\n",
    "f_data.text = f_data.text.apply(lambda x:re.sub('@[^\\s]+', '', x))\n",
    "f_data.text = f_data.text.apply(lambda x:re.sub(r'\\B#\\S+', \"\", x))\n",
    "f_data.text = f_data.text.apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "f_data.text = f_data.text.apply(lambda x:''.join(re.findall(r'\\w+', x)))\n",
    "f_data.text = f_data.text.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "f_data.text = f_data.text.apply(lambda x:re.sub(r'\\s+', '', x,flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409cf2d2-155b-46f6-ad33-7c7e5b11652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SIA()\n",
    "f_data['sentences'] = f_data['text'].apply(lambda x:sid.polarity_scores(''.join(re.findall(r'\\w+'.lower()))))\n",
    "f_data['Positive sentiment'] = f_data['sentiments'].apply(lambda x: x['pos']+1*(10**-6))\n",
    "f_data['Neutral Sentiment'] = f_data['sentiments'].apply(lambda x: x['neu']+1*(10**-6))\n",
    "f_data['Negative Sentiment'] = f_data['sentiments'].apply(lambda x: X['neg']+1(10**-6))\n",
    "\n",
    "f_data.drop(columns=['sentiments'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb690b5d-a475-4417-8636-0a5f6d04be07",
   "metadata": {},
   "source": [
    "# Exploraory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45aacb-5834-4371-954f-13b3eb867d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Distribution of sentiments', fontsize = 19, fontweight='bold')\n",
    "sns.kdeplot(f_data['Negative Sentiment'], bw=0.1)\n",
    "sns.kdeplot(f_data['Positive Sentiment'], bw=0.1)\n",
    "sns.kdeplot(f_data['Neutral Sentiment'], bw=0.1)\n",
    "plt.xlabel('Sentiment Value', fontsize=19)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Sentiments Across Tweets', fontsize=19, fontweight='bold')\n",
    "sns.kdeplot(f_data['Negative Sentiment'], bw=0.1, cumulative=True)\n",
    "sns.kdeplot(f_data['Positie Sentiment'], bw=0.1, cumulative=True)\n",
    "sns.kdeplot(f_data['Neutral Sentiment'], bw=0.1, cumulative=True)\n",
    "plt.xlabel('Sentiment Value', fontsize=19)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7cd78-823f-41d1-bb49-6feaf7753414",
   "metadata": {},
   "source": [
    "# Analyze Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a205f-e6e2-4c89-9597-05aec1012180",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = f_data.sort_values(by='date')\n",
    "ft_data = f_data.copy()\n",
    "ft_data['date'] = pd.to_datetime(f_data['date']).dt.date\n",
    "ft_data['year'] = pd.DatetimeIndex(ft_data['date']).year\n",
    "ft_data['month'] = pd.DatetimeIndex(ft_data['date']).month\n",
    "ft_data['day'] = pd.DatetimeIndex(ft_data['date']).day\n",
    "ft_data['day_of_year'] = pd.DatetimeIndex(ft_data['date']).dayofyear\n",
    "ft_data['quater'] = pd.DatetimeIndex(ft_data['date']).quater\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('A Cut-Off of Most Negative/ Positive Tweets', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax0 = sns.kdeplot(f_data['Negative Sentiment'], bw=0.1)\n",
    "kde_x, kde_y = ax0.lines[0].get_data()\n",
    "ax0.fill_between(kde_x, kde_y, where=(kde_x>0.25), interpolate=True, color='b')\n",
    "\n",
    "plt.annotate('Cut-off for Most Negative Tweets', xy=(0.25, 0.5), xytext = (0.4, 2), arrowprops=dict(facecolor='red', shrink=0.05, fontsize=16, fontweight='bold'))\n",
    "ax0.axvline(f_data['Negative Sentiment'].mean(), color='r', linestyle='--')\n",
    "ax0.axvline(f_data['Negative Sentiment'].median(), color='tab:orange', linestyle='-')\n",
    "plt.legend({'PDF': f_data['Negative Sentiment'], r'Mean: (:.2f)'.format(f_data['Negative Sentiment'].mean()):f_data['Negative Sentiment'].mean(),\n",
    "           r'Median: {:,.2f}'.format(f_data['Negative Sentiment'].median()):f_data['Negative Sentiment'].median()})\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "ax1 = sns.kdeplot(f_data['Positive Sentiment', bw=0.1, color='green')\n",
    "\n",
    "plt.annotate(\"Cut-Off for Most Positive Tweets\", xy=(0.4, 0.43), xytext=(0.4, 2),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05), fontsize=16, fontweight='bold'))\n",
    "kde_x, kde_y = ax1.line[0].get_data()\n",
    "ax1.fill_between(kde_x, kde_y, where = (kde_x>0.4), interpolate=True, color='green')\n",
    "ax1.set_xlabel('Sentiment Strength', fontsize=18)\n",
    "\n",
    "ax1.axvline(f_data['Positive Sentiment'].mean(), color='r', linestyle='--')\n",
    "ax1.axvline(f_data['Positive Sentiment'].median(), color= 'tab:orange', linestyle='-')\n",
    "plt.legend({'PDF':f_data['Positive Sentiment'], r'Mean: {:.2f}' .format(f_data['Positive Sentiment'].mean()):f_data['Positive Sentiment'].mean(),\n",
    "            r'Median: {:.2f}'.format(f_data['Positive Sentiment'].median()):f_data['Positive Sentiment'].median()})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d28586-5880-4ad1-b42b-f71874b7e4de",
   "metadata": {},
   "source": [
    "# Visualize Most Negative and Positive Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aecc4b-bf79-46cb-a5b4-8a5ad3e91048",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_positive = f-data[f_data['Positive Sentiment'].between(0.4, 1)]\n",
    "most_negative = f-data[f_data['Negative Sentiment'].between(0.25, 1)]\n",
    "\n",
    "most_positive_text = ''.join(most_positive.text)\n",
    "most_negative_text = ''.join(most_negative.text)\n",
    "\n",
    "pwc = WordCloud(width=600, height=400, collocations = False).generate(most_positive_text)\n",
    "nwc = WordCloud(width=600, height=400, collocations = False).generate(most_negative_text)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Common words among Positive Tweets\", fontsize = 16, fontweight='bold')\n",
    "plt.imshow(pwc)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Common Words among Negative Tweets\", fontsize = 16, fontweight='bold')\n",
    "plt.imshow(pwc)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db815a-4603-42d9-a0b5-02c9d18a2b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_t = most_positive_text\n",
    "\n",
    "wl_dict = dict()\n",
    "for word in l_t.split():\n",
    "    w = word.strip()\n",
    "    if w in STOPWORDS:\n",
    "        continue\n",
    "    else:\n",
    "        wl_dict[w] = wl_dict.get(w, 0)+1\n",
    "wl_dict = {k: v for k, v in sorted(wl_dict.items(), key= lambda item:item[1], rverse=True)}\n",
    "\n",
    "l_t = most_negative_text\n",
    "w2_dict = dict()\n",
    "for word in l_t.split():\n",
    "    w = word.strip()\n",
    "    if w in STOPWORDS:\n",
    "        continue\n",
    "    else:\n",
    "        w2_dict[w] = w2_dict.get(w, 0)+1\n",
    "w2_dict = {k: v for k, v in sorted(w2_dict.items(), key=lambda item; item[1], reverse= True)}\n",
    "\n",
    " top_10_pos = list(wl_dict.keys())[:10]\n",
    "top_10_neg = list(w2_dict.keys())[:10]\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "w_c = WordCloud(width=600, height=400, collocations = False, colormap='nipy_spectral').generate(''.join(top_10_pos))\n",
    "plt.title('Top 10 words in Most Positive tweets', fontsize = 19. fontweight='bold')\n",
    "plt.imshow(w_c)\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "w_c = w_c = WordCloud(width=600, height=400, collocations = False, colormap='nipy_spectral').generate(''.join(top_10_neg))\n",
    "plt.title('Top 10 words in Most Negative tweets', fontsize = 19. fontweight='bold')\n",
    "plt.imshow(w_c)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
